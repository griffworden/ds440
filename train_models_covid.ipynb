{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install TensorFlow\n",
    "!pip install tensorflow\n",
    "\n",
    "# Install Pandas\n",
    "!pip install pandas\n",
    "\n",
    "# Install Hugging Face Transformers\n",
    "!pip install transformers\n",
    "\n",
    "# Install NumPy\n",
    "!pip install numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\griff\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\griff\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from transformers import (\n",
    "    DistilBertTokenizer, TFDistilBertForSequenceClassification,\n",
    "    RobertaTokenizer, TFRobertaForSequenceClassification,\n",
    ")\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = pd.read_csv(\"./Data/Raw/Constraint_Val.csv\")[[\"tweet\", \"label\"]].rename(columns={\"tweet\": \"text\"})\n",
    "train_data = pd.read_csv(\"./Data/Raw/Constraint_Train.csv\")[[\"tweet\", \"label\"]].rename(columns={\"tweet\": \"text\"})\n",
    "def clean(df):\n",
    "    df = df.rename(columns={\"tweet\": \"text\"})\n",
    "    df['label'] = df['label'].map({'real': True, 'fake': False})\n",
    "    return df\n",
    "val_data = clean(val_data)\n",
    "train_data = clean(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chinese converting to Islam after realising th...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11 out of 13 people (from the Diamond Princess...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>COVID-19 Is Caused By A Bacterium, Not Virus A...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mike Pence in RNC speech praises Donald Trump’...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6/10 Sky's @EdConwaySky explains the latest #C...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2135</th>\n",
       "      <td>Donald Trump wrongly claimed that New Zealand ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2136</th>\n",
       "      <td>Current understanding is #COVID19 spreads most...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2137</th>\n",
       "      <td>Nothing screams “I am sat around doing fuck al...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2138</th>\n",
       "      <td>Birx says COVID-19 outbreak not under control ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2139</th>\n",
       "      <td>Another 4422 new coronavirus cases have been c...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2140 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label\n",
       "0     Chinese converting to Islam after realising th...  False\n",
       "1     11 out of 13 people (from the Diamond Princess...  False\n",
       "2     COVID-19 Is Caused By A Bacterium, Not Virus A...  False\n",
       "3     Mike Pence in RNC speech praises Donald Trump’...  False\n",
       "4     6/10 Sky's @EdConwaySky explains the latest #C...   True\n",
       "...                                                 ...    ...\n",
       "2135  Donald Trump wrongly claimed that New Zealand ...  False\n",
       "2136  Current understanding is #COVID19 spreads most...   True\n",
       "2137  Nothing screams “I am sat around doing fuck al...  False\n",
       "2138  Birx says COVID-19 outbreak not under control ...  False\n",
       "2139  Another 4422 new coronavirus cases have been c...   True\n",
       "\n",
       "[2140 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\griff\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFDistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of TFDistilBertForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaForSequenceClassification: ['roberta.embeddings.position_ids']\n",
      "- This IS expected if you are initializing TFRobertaForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFRobertaForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaForSequenceClassification: ['roberta.embeddings.position_ids']\n",
      "- This IS expected if you are initializing TFRobertaForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFRobertaForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# Load models and tokenizers as before\n",
    "distilbert_tokenizer = DistilBertTokenizer.from_pretrained('jojo0616/my_Misinformation_distilbert_model')\n",
    "distilbert_model = TFDistilBertForSequenceClassification.from_pretrained('jojo0616/my_Misinformation_distilbert_model', from_pt=True)\n",
    "\n",
    "roberta_tokenizer_v1 = RobertaTokenizer.from_pretrained('vikram71198/distilroberta-base-finetuned-fake-news-detection')\n",
    "roberta_model_v1 = TFRobertaForSequenceClassification.from_pretrained('vikram71198/distilroberta-base-finetuned-fake-news-detection', from_pt=True)\n",
    "\n",
    "roberta_tokenizer_v2 = RobertaTokenizer.from_pretrained('hamzab/roberta-fake-news-classification')\n",
    "roberta_model_v2 = TFRobertaForSequenceClassification.from_pretrained('hamzab/roberta-fake-news-classification', from_pt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = train_data['label'].tolist()\n",
    "train_text = train_data['text'].tolist()\n",
    "val_labels = val_data['label'].tolist()\n",
    "val_text = val_data['text'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\griff\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\griff\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "803/803 [==============================] - 5612s 7s/step - loss: 0.1094 - accuracy: 0.9609\n",
      "803/803 [==============================] - 4905s 6s/step - loss: 0.2263 - accuracy: 0.9114\n",
      "803/803 [==============================] - 9325s 12s/step - loss: 0.2413 - accuracy: 0.9107\n",
      "Models and tokenizers have been saved.\n"
     ]
    }
   ],
   "source": [
    "# Extended training function with saving functionality\n",
    "def train_and_save_model(model, tokenizer, texts, labels, model_save_path, epochs=3):\n",
    "    # Tokenize texts\n",
    "    inputs = tokenizer(texts, padding=True, truncation=True, return_tensors=\"tf\", max_length=512)\n",
    "    \n",
    "    # Convert labels to TensorFlow tensors\n",
    "    labels = tf.convert_to_tensor(labels)\n",
    "\n",
    "    # Create a TensorFlow dataset\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(inputs), labels)).batch(8)\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "    \n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(dataset, epochs=epochs)\n",
    "    \n",
    "    # Save the model and tokenizer\n",
    "    model.save_pretrained(model_save_path)\n",
    "    tokenizer.save_pretrained(model_save_path)\n",
    "\n",
    "# Convert labels to TensorFlow tensors\n",
    "labels_tensor = tf.convert_to_tensor(train_labels)\n",
    "\n",
    "# No need to pre-tokenize the train_text. Pass raw text directly.\n",
    "# Specify the save paths for each model\n",
    "distilbert_save_path = './distilbert_finetuned'\n",
    "roberta_v1_save_path = './roberta_v1_finetuned'\n",
    "roberta_v2_save_path = './roberta_v2_finetuned'\n",
    "\n",
    "# Train and save each model. Note that we're now passing `train_text` and `labels_tensor` directly.\n",
    "train_and_save_model(distilbert_model, distilbert_tokenizer, train_text, labels_tensor, distilbert_save_path, epochs=1)\n",
    "train_and_save_model(roberta_model_v1, roberta_tokenizer_v1, train_text, labels_tensor, roberta_v1_save_path, epochs=1)\n",
    "train_and_save_model(roberta_model_v2, roberta_tokenizer_v2, train_text, labels_tensor, roberta_v2_save_path, epochs=1)\n",
    "\n",
    "print(\"Models and tokenizers have been saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\griff\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFDistilBertForSequenceClassification.\n",
      "\n",
      "All the layers of TFDistilBertForSequenceClassification were initialized from the model checkpoint at ./distilbert_finetuned.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\n",
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at ./roberta_v1_finetuned.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n",
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at ./roberta_v2_finetuned.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# Load the fine-tuned DistilBERT model and tokenizer\n",
    "distilbert_tokenizer = DistilBertTokenizer.from_pretrained('./distilbert_finetuned')\n",
    "distilbert_model = TFDistilBertForSequenceClassification.from_pretrained('./distilbert_finetuned')\n",
    "\n",
    "# Load the fine-tuned RoBERTa model and tokenizer for the first variant\n",
    "roberta_tokenizer_v1 = RobertaTokenizer.from_pretrained('./roberta_v1_finetuned')\n",
    "roberta_model_v1 = TFRobertaForSequenceClassification.from_pretrained('./roberta_v1_finetuned')\n",
    "\n",
    "# Load the fine-tuned RoBERTa model and tokenizer for the second variant\n",
    "roberta_tokenizer_v2 = RobertaTokenizer.from_pretrained('./roberta_v2_finetuned')\n",
    "roberta_model_v2 = TFRobertaForSequenceClassification.from_pretrained('./roberta_v2_finetuned')\n",
    "\n",
    "def ensemble_classify_news_and_evaluate_accuracy(df):\n",
    "    # Lists to store individual model predictions\n",
    "    distilbert_predictions = []\n",
    "    roberta_v1_predictions = []\n",
    "    roberta_v2_predictions = []\n",
    "    ensemble_predictions = []\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        text_input = row['text']\n",
    "\n",
    "        # Prepare inputs and get probabilities for DistilBERT\n",
    "        distilbert_inputs = distilbert_tokenizer(text_input, return_tensors=\"tf\", truncation=True, padding='max_length', max_length=512)\n",
    "        distilbert_outputs = distilbert_model(distilbert_inputs)\n",
    "        distilbert_probabilities = tf.nn.softmax(distilbert_outputs.logits, axis=-1)\n",
    "        distilbert_predicted_class_index = tf.argmax(distilbert_probabilities, axis=-1).numpy()[0]\n",
    "        distilbert_predictions.append(True if distilbert_predicted_class_index == 1 else False)\n",
    "\n",
    "        # Prepare inputs and get probabilities for RoBERTa variant 1\n",
    "        roberta_inputs_v1 = roberta_tokenizer_v1(text_input, return_tensors=\"tf\", truncation=True, padding='max_length', max_length=512)\n",
    "        roberta_outputs_v1 = roberta_model_v1(roberta_inputs_v1)\n",
    "        roberta_probabilities_v1 = tf.nn.softmax(roberta_outputs_v1.logits, axis=-1)\n",
    "        roberta_v1_predicted_class_index = tf.argmax(roberta_probabilities_v1, axis=-1).numpy()[0]\n",
    "        roberta_v1_predictions.append(True if roberta_v1_predicted_class_index == 1 else False)\n",
    "\n",
    "        # Prepare inputs and get probabilities for RoBERTa variant 2\n",
    "        roberta_inputs_v2 = roberta_tokenizer_v2(text_input, return_tensors=\"tf\", truncation=True, padding='max_length', max_length=512)\n",
    "        roberta_outputs_v2 = roberta_model_v2(roberta_inputs_v2)\n",
    "        roberta_probabilities_v2 = tf.nn.softmax(roberta_outputs_v2.logits, axis=-1)\n",
    "        roberta_v2_predicted_class_index = tf.argmax(roberta_probabilities_v2, axis=-1).numpy()[0]\n",
    "        roberta_v2_predictions.append(True if roberta_v2_predicted_class_index == 1 else False)\n",
    "\n",
    "        # Ensemble: Average the probabilities from all models\n",
    "        avg_probabilities = (distilbert_probabilities + roberta_probabilities_v1 + roberta_probabilities_v2) / 3\n",
    "        predicted_class_index = tf.argmax(avg_probabilities, axis=-1).numpy()[0]\n",
    "        ensemble_predictions.append(True if predicted_class_index == 1 else False)\n",
    "\n",
    "    # Adding predictions to the DataFrame\n",
    "    df['DistilBERTPrediction'] = distilbert_predictions\n",
    "    df['RoBERTaV1Prediction'] = roberta_v1_predictions\n",
    "    df['RoBERTaV2Prediction'] = roberta_v2_predictions\n",
    "    df['EnsemblePrediction'] = ensemble_predictions\n",
    "    \n",
    "    # Calculate and print the accuracy for the ensemble predictions\n",
    "    correct_predictions = (df['EnsemblePrediction'] == df['label']).sum()\n",
    "    total_predictions = len(df)\n",
    "    accuracy = correct_predictions / total_predictions\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9799\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>DistilBERTPrediction</th>\n",
       "      <th>RoBERTaV1Prediction</th>\n",
       "      <th>RoBERTaV2Prediction</th>\n",
       "      <th>EnsemblePrediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chinese converting to Islam after realising th...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11 out of 13 people (from the Diamond Princess...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>COVID-19 Is Caused By A Bacterium, Not Virus A...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mike Pence in RNC speech praises Donald Trump’...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6/10 Sky's @EdConwaySky explains the latest #C...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2135</th>\n",
       "      <td>Donald Trump wrongly claimed that New Zealand ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2136</th>\n",
       "      <td>Current understanding is #COVID19 spreads most...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2137</th>\n",
       "      <td>Nothing screams “I am sat around doing fuck al...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2138</th>\n",
       "      <td>Birx says COVID-19 outbreak not under control ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2139</th>\n",
       "      <td>Another 4422 new coronavirus cases have been c...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2140 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label  \\\n",
       "0     Chinese converting to Islam after realising th...  False   \n",
       "1     11 out of 13 people (from the Diamond Princess...  False   \n",
       "2     COVID-19 Is Caused By A Bacterium, Not Virus A...  False   \n",
       "3     Mike Pence in RNC speech praises Donald Trump’...  False   \n",
       "4     6/10 Sky's @EdConwaySky explains the latest #C...   True   \n",
       "...                                                 ...    ...   \n",
       "2135  Donald Trump wrongly claimed that New Zealand ...  False   \n",
       "2136  Current understanding is #COVID19 spreads most...   True   \n",
       "2137  Nothing screams “I am sat around doing fuck al...  False   \n",
       "2138  Birx says COVID-19 outbreak not under control ...  False   \n",
       "2139  Another 4422 new coronavirus cases have been c...   True   \n",
       "\n",
       "      DistilBERTPrediction  RoBERTaV1Prediction  RoBERTaV2Prediction  \\\n",
       "0                    False                False                False   \n",
       "1                    False                False                False   \n",
       "2                    False                False                False   \n",
       "3                    False                False                False   \n",
       "4                     True                 True                 True   \n",
       "...                    ...                  ...                  ...   \n",
       "2135                 False                False                False   \n",
       "2136                  True                 True                 True   \n",
       "2137                 False                False                False   \n",
       "2138                 False                 True                False   \n",
       "2139                  True                 True                 True   \n",
       "\n",
       "      EnsemblePrediction  \n",
       "0                  False  \n",
       "1                  False  \n",
       "2                  False  \n",
       "3                  False  \n",
       "4                   True  \n",
       "...                  ...  \n",
       "2135               False  \n",
       "2136                True  \n",
       "2137               False  \n",
       "2138               False  \n",
       "2139                True  \n",
       "\n",
       "[2140 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_updated = ensemble_classify_news_and_evaluate_accuracy(val_data)\n",
    "display(df_updated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_updated.rename(columns={\n",
    "    'DistilBERTPrediction': 'DistilBERTPrediction_Text',\n",
    "    'RoBERTaV1Prediction': 'RoBERTaV1Prediction_Text',\n",
    "    'RoBERTaV2Prediction': 'RoBERTaV2Prediction_Text',\n",
    "    'EnsemblePrediction': 'EnsemblePrediction_Text'\n",
    "}, inplace=True)\n",
    "df_updated.to_csv(\"./Data/Processed/Constraint_Val_Labeled.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
