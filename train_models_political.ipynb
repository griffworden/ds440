{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorflow in /storage/icds/RISE/sw8/anaconda3-2021.11/conda_envs/tensorflow/lib/python3.10/site-packages (2.8.0)\n",
      "Requirement already satisfied: tensorboard<2.9,>=2.8 in /storage/icds/RISE/sw8/anaconda3-2021.11/conda_envs/tensorflow/lib/python3.10/site-packages (from tensorflow) (2.8.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /storage/icds/RISE/sw8/anaconda3-2021.11/conda_envs/tensorflow/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: numpy>=1.20 in /storage/icds/RISE/sw8/anaconda3-2021.11/conda_envs/tensorflow/lib/python3.10/site-packages (from tensorflow) (1.22.3)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /storage/icds/RISE/sw8/anaconda3-2021.11/conda_envs/tensorflow/lib/python3.10/site-packages (from tensorflow) (3.6.0)\n",
      "Requirement already satisfied: flatbuffers>=1.12 in /storage/icds/RISE/sw8/anaconda3-2021.11/conda_envs/tensorflow/lib/python3.10/site-packages (from tensorflow) (2.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /storage/icds/RISE/sw8/anaconda3-2021.11/conda_envs/tensorflow/lib/python3.10/site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: setuptools in /storage/icds/RISE/sw8/anaconda3-2021.11/conda_envs/tensorflow/lib/python3.10/site-packages (from tensorflow) (60.10.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /storage/icds/RISE/sw8/anaconda3-2021.11/conda_envs/tensorflow/lib/python3.10/site-packages (from tensorflow) (1.14.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /storage/icds/RISE/sw8/anaconda3-2021.11/conda_envs/tensorflow/lib/python3.10/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: libclang>=9.0.1 in /storage/icds/RISE/sw8/anaconda3-2021.11/conda_envs/tensorflow/lib/python3.10/site-packages (from tensorflow) (13.0.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /storage/icds/RISE/sw8/anaconda3-2021.11/conda_envs/tensorflow/lib/python3.10/site-packages (from tensorflow) (1.44.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /storage/icds/RISE/sw8/anaconda3-2021.11/conda_envs/tensorflow/lib/python3.10/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /storage/icds/RISE/sw8/anaconda3-2021.11/conda_envs/tensorflow/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /storage/icds/RISE/sw8/anaconda3-2021.11/conda_envs/tensorflow/lib/python3.10/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /storage/icds/RISE/sw8/anaconda3-2021.11/conda_envs/tensorflow/lib/python3.10/site-packages (from tensorflow) (4.1.1)\n",
      "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /storage/icds/RISE/sw8/anaconda3-2021.11/conda_envs/tensorflow/lib/python3.10/site-packages (from tensorflow) (2.8.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /storage/icds/RISE/sw8/anaconda3-2021.11/conda_envs/tensorflow/lib/python3.10/site-packages (from tensorflow) (3.19.4)\n",
      "Requirement already satisfied: gast>=0.2.1 in /storage/icds/RISE/sw8/anaconda3-2021.11/conda_envs/tensorflow/lib/python3.10/site-packages (from tensorflow) (0.5.3)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /storage/icds/RISE/sw8/anaconda3-2021.11/conda_envs/tensorflow/lib/python3.10/site-packages (from tensorflow) (0.24.0)\n",
      "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in /storage/icds/RISE/sw8/anaconda3-2021.11/conda_envs/tensorflow/lib/python3.10/site-packages (from tensorflow) (2.8.0.dev2021122109)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in /storage/icds/RISE/sw8/anaconda3-2021.11/conda_envs/tensorflow/lib/python3.10/site-packages (from tensorflow) (1.0.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /storage/icds/RISE/sw8/anaconda3-2021.11/conda_envs/tensorflow/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /storage/icds/RISE/sw8/anaconda3-2021.11/conda_envs/tensorflow/lib/python3.10/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.6.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /storage/icds/RISE/sw8/anaconda3-2021.11/conda_envs/tensorflow/lib/python3.10/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /storage/icds/RISE/sw8/anaconda3-2021.11/conda_envs/tensorflow/lib/python3.10/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /storage/icds/RISE/sw8/anaconda3-2021.11/conda_envs/tensorflow/lib/python3.10/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /storage/icds/RISE/sw8/anaconda3-2021.11/conda_envs/tensorflow/lib/python3.10/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /storage/icds/RISE/sw8/anaconda3-2021.11/conda_envs/tensorflow/lib/python3.10/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.0.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /storage/icds/RISE/sw8/anaconda3-2021.11/conda_envs/tensorflow/lib/python3.10/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.25.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /storage/icds/RISE/sw8/anaconda3-2021.11/conda_envs/tensorflow/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /storage/icds/RISE/sw8/anaconda3-2021.11/conda_envs/tensorflow/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /storage/icds/RISE/sw8/anaconda3-2021.11/conda_envs/tensorflow/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (5.0.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /storage/icds/RISE/sw8/anaconda3-2021.11/conda_envs/tensorflow/lib/python3.10/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /storage/icds/RISE/sw8/anaconda3-2021.11/conda_envs/tensorflow/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /storage/icds/RISE/sw8/anaconda3-2021.11/conda_envs/tensorflow/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /storage/icds/RISE/sw8/anaconda3-2021.11/conda_envs/tensorflow/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /storage/icds/RISE/sw8/anaconda3-2021.11/conda_envs/tensorflow/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2023.5.7)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /storage/icds/RISE/sw8/anaconda3-2021.11/conda_envs/tensorflow/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /storage/icds/RISE/sw8/anaconda3-2021.11/conda_envs/tensorflow/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in /storage/icds/RISE/sw8/anaconda3-2021.11/conda_envs/tensorflow/lib/python3.10/site-packages (1.4.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /storage/icds/RISE/sw8/anaconda3-2021.11/conda_envs/tensorflow/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /storage/icds/RISE/sw8/anaconda3-2021.11/conda_envs/tensorflow/lib/python3.10/site-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /storage/icds/RISE/sw8/anaconda3-2021.11/conda_envs/tensorflow/lib/python3.10/site-packages (from pandas) (1.22.3)\n",
      "Requirement already satisfied: six>=1.5 in /storage/icds/RISE/sw8/anaconda3-2021.11/conda_envs/tensorflow/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in /storage/icds/RISE/sw8/anaconda3-2021.11/conda_envs/tensorflow/lib/python3.10/site-packages (4.26.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /storage/icds/RISE/sw8/anaconda3-2021.11/conda_envs/tensorflow/lib/python3.10/site-packages (from transformers) (0.13.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /storage/icds/RISE/sw8/anaconda3-2021.11/conda_envs/tensorflow/lib/python3.10/site-packages (from transformers) (0.12.0)\n",
      "Requirement already satisfied: filelock in /storage/icds/RISE/sw8/anaconda3-2021.11/conda_envs/tensorflow/lib/python3.10/site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /storage/icds/RISE/sw8/anaconda3-2021.11/conda_envs/tensorflow/lib/python3.10/site-packages (from transformers) (1.22.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /storage/icds/RISE/sw8/anaconda3-2021.11/conda_envs/tensorflow/lib/python3.10/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /storage/icds/RISE/sw8/anaconda3-2021.11/conda_envs/tensorflow/lib/python3.10/site-packages (from transformers) (2022.9.13)\n",
      "Requirement already satisfied: packaging>=20.0 in /storage/icds/RISE/sw8/anaconda3-2021.11/conda_envs/tensorflow/lib/python3.10/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: requests in /storage/icds/RISE/sw8/anaconda3-2021.11/conda_envs/tensorflow/lib/python3.10/site-packages (from transformers) (2.25.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /storage/icds/RISE/sw8/anaconda3-2021.11/conda_envs/tensorflow/lib/python3.10/site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /storage/icds/RISE/sw8/anaconda3-2021.11/conda_envs/tensorflow/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /storage/icds/RISE/sw8/anaconda3-2021.11/conda_envs/tensorflow/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.7)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /storage/icds/RISE/sw8/anaconda3-2021.11/conda_envs/tensorflow/lib/python3.10/site-packages (from requests->transformers) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /storage/icds/RISE/sw8/anaconda3-2021.11/conda_envs/tensorflow/lib/python3.10/site-packages (from requests->transformers) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /storage/icds/RISE/sw8/anaconda3-2021.11/conda_envs/tensorflow/lib/python3.10/site-packages (from requests->transformers) (2023.5.7)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /storage/icds/RISE/sw8/anaconda3-2021.11/conda_envs/tensorflow/lib/python3.10/site-packages (from requests->transformers) (2.10)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy in /storage/icds/RISE/sw8/anaconda3-2021.11/conda_envs/tensorflow/lib/python3.10/site-packages (1.22.3)\n"
     ]
    }
   ],
   "source": [
    "# Install TensorFlow\n",
    "!pip install tensorflow\n",
    "\n",
    "# Install Pandas\n",
    "!pip install pandas\n",
    "\n",
    "# Install Hugging Face Transformers\n",
    "!pip install transformers\n",
    "\n",
    "# Install NumPy\n",
    "!pip install numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage/icds/RISE/sw8/anaconda/conda_envs/tensorflow/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from transformers import (\n",
    "    DistilBertTokenizer, TFDistilBertForSequenceClassification,\n",
    "    RobertaTokenizer, TFRobertaForSequenceClassification,\n",
    ")\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = pd.read_csv(\"./test_data.csv\")[[\"text\", \"label\"]]\n",
    "train_data = pd.read_csv(\"./train_data.csv\")[[\"text\", \"label\"]]\n",
    "def clean(df):\n",
    "    df['label'] = df['label'].map({'Real': True, 'Fake': False})\n",
    "    return df\n",
    "val_data = clean(val_data)\n",
    "train_data = clean(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Obama Blasts Trump At Veterans Event For Trash...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Thirteen Chinese fishermen die as boat collide...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Far-right presidential hopeful aims to be Braz...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Defying warnings, residents refuse to leave Mu...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Anti-Uber protests disrupt major Chilean airpo...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4487</th>\n",
       "      <td>Boiler Room EP #130  Mandalay Cover-Up</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4488</th>\n",
       "      <td>WATCH: HANOI JANE FONDA Had Chance To Expose S...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4489</th>\n",
       "      <td>Islamic State seizes new Afghan foothold after...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4490</th>\n",
       "      <td>Japan to impose additional sanctions on North ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4491</th>\n",
       "      <td>EP #11: Patrick Henningsen LIVE  Top Trump Tre...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4492 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label\n",
       "0     Obama Blasts Trump At Veterans Event For Trash...  False\n",
       "1     Thirteen Chinese fishermen die as boat collide...   True\n",
       "2     Far-right presidential hopeful aims to be Braz...   True\n",
       "3     Defying warnings, residents refuse to leave Mu...   True\n",
       "4     Anti-Uber protests disrupt major Chilean airpo...   True\n",
       "...                                                 ...    ...\n",
       "4487             Boiler Room EP #130  Mandalay Cover-Up  False\n",
       "4488  WATCH: HANOI JANE FONDA Had Chance To Expose S...  False\n",
       "4489  Islamic State seizes new Afghan foothold after...   True\n",
       "4490  Japan to impose additional sanctions on North ...   True\n",
       "4491  EP #11: Patrick Henningsen LIVE  Top Trump Tre...  False\n",
       "\n",
       "[4492 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anthem to pare back Obamacare offerings in Nev...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IF THESE CELEBRITIES ARE With Her Then Why Is ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VA chief presses Congress to make it easier to...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FALSE NARRATIVE EXPOSED: CASTILE WAS ARMED ROB...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Both pro and anti-Brexit lawmakers back oustin...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40418</th>\n",
       "      <td>Nigeria says U.S. agrees delayed $593 million ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40419</th>\n",
       "      <td>VIDEO: Top 10 Most Embarrassing Presidential F...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40420</th>\n",
       "      <td>DELEGATES FOR DUMMIES: How Theyre AwardedAnd H...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40421</th>\n",
       "      <td>Republican tax plan would deal financial hit t...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40422</th>\n",
       "      <td>U.N. refugee commissioner says Australia must ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40423 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "0      Anthem to pare back Obamacare offerings in Nev...   True\n",
       "1      IF THESE CELEBRITIES ARE With Her Then Why Is ...  False\n",
       "2      VA chief presses Congress to make it easier to...   True\n",
       "3      FALSE NARRATIVE EXPOSED: CASTILE WAS ARMED ROB...  False\n",
       "4      Both pro and anti-Brexit lawmakers back oustin...   True\n",
       "...                                                  ...    ...\n",
       "40418  Nigeria says U.S. agrees delayed $593 million ...   True\n",
       "40419  VIDEO: Top 10 Most Embarrassing Presidential F...  False\n",
       "40420  DELEGATES FOR DUMMIES: How Theyre AwardedAnd H...  False\n",
       "40421  Republican tax plan would deal financial hit t...   True\n",
       "40422  U.N. refugee commissioner says Australia must ...   True\n",
       "\n",
       "[40423 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(val_data)\n",
    "display(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 21:38:02.582681: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-23 21:38:07.191494: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38402 MB memory:  -> device: 0, name: NVIDIA A40, pci bus id: 0000:2b:00.0, compute capability: 8.6\n",
      "2024-10-23 21:38:07.769109: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "2024-10-23 21:38:10.804597: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "All PyTorch model weights were used when initializing TFDistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of TFDistilBertForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaForSequenceClassification: ['roberta.embeddings.position_ids']\n",
      "- This IS expected if you are initializing TFRobertaForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFRobertaForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaForSequenceClassification: ['roberta.embeddings.position_ids']\n",
      "- This IS expected if you are initializing TFRobertaForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFRobertaForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# Load models and tokenizers as before\n",
    "distilbert_tokenizer = DistilBertTokenizer.from_pretrained('jojo0616/my_Misinformation_distilbert_model')\n",
    "distilbert_model = TFDistilBertForSequenceClassification.from_pretrained('jojo0616/my_Misinformation_distilbert_model', from_pt=True)\n",
    "\n",
    "roberta_tokenizer_v1 = RobertaTokenizer.from_pretrained('vikram71198/distilroberta-base-finetuned-fake-news-detection')\n",
    "roberta_model_v1 = TFRobertaForSequenceClassification.from_pretrained('vikram71198/distilroberta-base-finetuned-fake-news-detection', from_pt=True)\n",
    "\n",
    "roberta_tokenizer_v2 = RobertaTokenizer.from_pretrained('hamzab/roberta-fake-news-classification')\n",
    "roberta_model_v2 = TFRobertaForSequenceClassification.from_pretrained('hamzab/roberta-fake-news-classification', from_pt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = train_data['label'].tolist()\n",
    "train_text = train_data['text'].tolist()\n",
    "val_labels = val_data['label'].tolist()\n",
    "val_text = val_data['text'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "4548/4548 [==============================] - 184s 39ms/step - loss: 0.0830 - accuracy: 0.9699 - val_loss: 0.0242 - val_accuracy: 0.9936 - lr: 5.0000e-05\n",
      "Epoch 2/5\n",
      "4548/4548 [==============================] - 178s 39ms/step - loss: 0.0218 - accuracy: 0.9927 - val_loss: 0.0058 - val_accuracy: 0.9980 - lr: 5.0000e-05\n",
      "Epoch 4/5\n",
      "3165/4548 [===================>..........] - ETA: 51s - loss: 0.0150 - accuracy: 0.9952"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4548/4548 [==============================] - 179s 39ms/step - loss: 0.0160 - accuracy: 0.9953 - val_loss: 0.0049 - val_accuracy: 0.9985 - lr: 5.0000e-05\n",
      "Epoch 5/5\n",
      "4548/4548 [==============================] - 213s 46ms/step - loss: 0.0385 - accuracy: 0.9900 - val_loss: 0.0290 - val_accuracy: 0.9948 - lr: 5.0000e-05\n",
      "4548/4548 [==============================] - 363s 78ms/step - loss: 0.3565 - accuracy: 0.7587 - val_loss: 0.6921 - val_accuracy: 0.5293 - lr: 5.0000e-05\n",
      "Epoch 2/5\n",
      "4548/4548 [==============================] - 353s 78ms/step - loss: 0.6946 - accuracy: 0.5166 - val_loss: 0.6918 - val_accuracy: 0.5303 - lr: 5.0000e-05\n",
      "Epoch 3/5\n",
      "4548/4548 [==============================] - 352s 77ms/step - loss: 0.6841 - accuracy: 0.5274 - val_loss: 0.6960 - val_accuracy: 0.5271 - lr: 5.0000e-05\n",
      "Epoch 4/5\n",
      "4548/4548 [==============================] - 354s 78ms/step - loss: 0.4486 - accuracy: 0.6996 - val_loss: 0.1029 - val_accuracy: 0.9743 - lr: 5.0000e-05\n",
      "Epoch 5/5\n",
      "4548/4548 [==============================] - 354s 78ms/step - loss: 0.0953 - accuracy: 0.9771 - val_loss: 0.0791 - val_accuracy: 0.9819 - lr: 5.0000e-05\n",
      "Models and tokenizers have been saved.\n"
     ]
    }
   ],
   "source": [
    "def train_and_save_model(model, tokenizer, texts, labels, model_save_path, epochs=3):\n",
    "    # Tokenize texts\n",
    "    inputs = tokenizer(texts, padding=True, truncation=True, return_tensors=\"tf\", max_length=512)\n",
    "    \n",
    "    # Convert labels to TensorFlow tensors\n",
    "    labels = tf.convert_to_tensor(labels)\n",
    "\n",
    "    # Create a TensorFlow dataset\n",
    "    full_dataset = tf.data.Dataset.from_tensor_slices((dict(inputs), labels)).shuffle(len(labels))\n",
    "\n",
    "    # Calculate the number of samples for training (90%) and validation (10%)\n",
    "    train_size = int(0.9 * len(labels))\n",
    "    val_size = len(labels) - train_size\n",
    "\n",
    "    # Split the dataset into training and validation\n",
    "    train_dataset = full_dataset.take(train_size).batch(8)\n",
    "    val_dataset = full_dataset.skip(train_size).batch(8)\n",
    "    \n",
    "    # Define initial learning rate\n",
    "    initial_learning_rate = 5e-5\n",
    "    \n",
    "    # Define learning rate schedule\n",
    "    def lr_scheduler(epoch, lr):\n",
    "        if epoch < 10:\n",
    "            return lr\n",
    "        else:\n",
    "            return lr * tf.math.exp(-0.1)\n",
    "    \n",
    "    # Learning Rate Scheduler callback\n",
    "    scheduler = tf.keras.callbacks.LearningRateScheduler(lr_scheduler)\n",
    "    \n",
    "    # Early Stopping callback\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=initial_learning_rate)\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "    \n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
    "    \n",
    "    # Train the model with learning rate scheduler, early stopping, and the validation set\n",
    "    model.fit(train_dataset, epochs=epochs, validation_data=val_dataset, callbacks=[scheduler, early_stopping])\n",
    "    \n",
    "    # Save the model and tokenizer\n",
    "    model.save_pretrained(model_save_path)\n",
    "    tokenizer.save_pretrained(model_save_path)\n",
    "\n",
    "# Convert labels to TensorFlow tensors\n",
    "labels_tensor = tf.convert_to_tensor(train_labels)\n",
    "\n",
    "# No need to pre-tokenize the train_text. Pass raw text directly.\n",
    "# Specify the save paths for each model\n",
    "distilbert_save_path = './distilbert_finetuned_political'\n",
    "roberta_v1_save_path = './roberta_v1_finetuned_political'\n",
    "roberta_v2_save_path = './roberta_v2_finetuned_political'\n",
    "\n",
    "# Train and save each model. Note that we're now passing `train_text` and `labels_tensor` directly.\n",
    "train_and_save_model(distilbert_model, distilbert_tokenizer, train_text, labels_tensor, distilbert_save_path, epochs=5)\n",
    "train_and_save_model(roberta_model_v1, roberta_tokenizer_v1, train_text, labels_tensor, roberta_v1_save_path, epochs=5)\n",
    "train_and_save_model(roberta_model_v2, roberta_tokenizer_v2, train_text, labels_tensor, roberta_v2_save_path, epochs=5)\n",
    "\n",
    "print(\"Models and tokenizers have been saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at ./distilbert_finetuned_political were not used when initializing TFDistilBertForSequenceClassification: ['dropout_19']\n",
      "- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at ./distilbert_finetuned_political and are newly initialized: ['dropout_97']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at ./roberta_v1_finetuned_political.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n",
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at ./roberta_v2_finetuned_political.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# Load the fine-tuned DistilBERT model and tokenizer\n",
    "distilbert_tokenizer = DistilBertTokenizer.from_pretrained('./distilbert_finetuned_political')\n",
    "distilbert_model = TFDistilBertForSequenceClassification.from_pretrained('./distilbert_finetuned_political')\n",
    "\n",
    "# Load the fine-tuned RoBERTa model and tokenizer for the first variant\n",
    "roberta_tokenizer_v1 = RobertaTokenizer.from_pretrained('./roberta_v1_finetuned_political')\n",
    "roberta_model_v1 = TFRobertaForSequenceClassification.from_pretrained('./roberta_v1_finetuned_political')\n",
    "\n",
    "# Load the fine-tuned RoBERTa model and tokenizer for the second variant\n",
    "roberta_tokenizer_v2 = RobertaTokenizer.from_pretrained('./roberta_v2_finetuned_political')\n",
    "roberta_model_v2 = TFRobertaForSequenceClassification.from_pretrained('./roberta_v2_finetuned_political')\n",
    "\n",
    "def ensemble_classify_news_and_evaluate_accuracy(df):\n",
    "    # Lists to store individual model predictions\n",
    "    distilbert_predictions = []\n",
    "    roberta_v1_predictions = []\n",
    "    roberta_v2_predictions = []\n",
    "    ensemble_predictions = []\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        text_input = row['text']\n",
    "\n",
    "        # Prepare inputs and get probabilities for DistilBERT\n",
    "        distilbert_inputs = distilbert_tokenizer(text_input, return_tensors=\"tf\", truncation=True, padding='max_length', max_length=512)\n",
    "        distilbert_outputs = distilbert_model(distilbert_inputs)\n",
    "        distilbert_probabilities = tf.nn.softmax(distilbert_outputs.logits, axis=-1)\n",
    "        distilbert_predicted_class_index = tf.argmax(distilbert_probabilities, axis=-1).numpy()[0]\n",
    "        distilbert_predictions.append(True if distilbert_predicted_class_index == 1 else False)\n",
    "\n",
    "        # Prepare inputs and get probabilities for RoBERTa variant 1\n",
    "        roberta_inputs_v1 = roberta_tokenizer_v1(text_input, return_tensors=\"tf\", truncation=True, padding='max_length', max_length=512)\n",
    "        roberta_outputs_v1 = roberta_model_v1(roberta_inputs_v1)\n",
    "        roberta_probabilities_v1 = tf.nn.softmax(roberta_outputs_v1.logits, axis=-1)\n",
    "        roberta_v1_predicted_class_index = tf.argmax(roberta_probabilities_v1, axis=-1).numpy()[0]\n",
    "        roberta_v1_predictions.append(True if roberta_v1_predicted_class_index == 1 else False)\n",
    "\n",
    "        # Prepare inputs and get probabilities for RoBERTa variant 2\n",
    "        roberta_inputs_v2 = roberta_tokenizer_v2(text_input, return_tensors=\"tf\", truncation=True, padding='max_length', max_length=512)\n",
    "        roberta_outputs_v2 = roberta_model_v2(roberta_inputs_v2)\n",
    "        roberta_probabilities_v2 = tf.nn.softmax(roberta_outputs_v2.logits, axis=-1)\n",
    "        roberta_v2_predicted_class_index = tf.argmax(roberta_probabilities_v2, axis=-1).numpy()[0]\n",
    "        roberta_v2_predictions.append(True if roberta_v2_predicted_class_index == 1 else False)\n",
    "\n",
    "        # Ensemble: Average the probabilities from all models\n",
    "        avg_probabilities = (distilbert_probabilities + roberta_probabilities_v1 + roberta_probabilities_v2) / 3\n",
    "        predicted_class_index = tf.argmax(avg_probabilities, axis=-1).numpy()[0]\n",
    "        ensemble_predictions.append(True if predicted_class_index == 1 else False)\n",
    "\n",
    "    # Adding predictions to the DataFrame\n",
    "    df['DistilBERTPrediction'] = distilbert_predictions\n",
    "    df['RoBERTaV1Prediction'] = roberta_v1_predictions\n",
    "    df['RoBERTaV2Prediction'] = roberta_v2_predictions\n",
    "    df['EnsemblePrediction'] = ensemble_predictions\n",
    "    \n",
    "    # Calculate and print the accuracy for the ensemble predictions\n",
    "    correct_predictions = (df['EnsemblePrediction'] == df['label']).sum()\n",
    "    total_predictions = len(df)\n",
    "    accuracy = correct_predictions / total_predictions\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9931\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>DistilBERTPrediction</th>\n",
       "      <th>RoBERTaV1Prediction</th>\n",
       "      <th>RoBERTaV2Prediction</th>\n",
       "      <th>EnsemblePrediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Obama Blasts Trump At Veterans Event For Trash...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Thirteen Chinese fishermen die as boat collide...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Far-right presidential hopeful aims to be Braz...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Defying warnings, residents refuse to leave Mu...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Anti-Uber protests disrupt major Chilean airpo...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4487</th>\n",
       "      <td>Boiler Room EP #130  Mandalay Cover-Up</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4488</th>\n",
       "      <td>WATCH: HANOI JANE FONDA Had Chance To Expose S...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4489</th>\n",
       "      <td>Islamic State seizes new Afghan foothold after...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4490</th>\n",
       "      <td>Japan to impose additional sanctions on North ...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4491</th>\n",
       "      <td>EP #11: Patrick Henningsen LIVE  Top Trump Tre...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4492 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label  \\\n",
       "0     Obama Blasts Trump At Veterans Event For Trash...  False   \n",
       "1     Thirteen Chinese fishermen die as boat collide...   True   \n",
       "2     Far-right presidential hopeful aims to be Braz...   True   \n",
       "3     Defying warnings, residents refuse to leave Mu...   True   \n",
       "4     Anti-Uber protests disrupt major Chilean airpo...   True   \n",
       "...                                                 ...    ...   \n",
       "4487             Boiler Room EP #130  Mandalay Cover-Up  False   \n",
       "4488  WATCH: HANOI JANE FONDA Had Chance To Expose S...  False   \n",
       "4489  Islamic State seizes new Afghan foothold after...   True   \n",
       "4490  Japan to impose additional sanctions on North ...   True   \n",
       "4491  EP #11: Patrick Henningsen LIVE  Top Trump Tre...  False   \n",
       "\n",
       "      DistilBERTPrediction  RoBERTaV1Prediction  RoBERTaV2Prediction  \\\n",
       "0                    False                False                False   \n",
       "1                     True                 True                 True   \n",
       "2                     True                 True                 True   \n",
       "3                     True                 True                 True   \n",
       "4                     True                 True                 True   \n",
       "...                    ...                  ...                  ...   \n",
       "4487                 False                False                 True   \n",
       "4488                 False                False                False   \n",
       "4489                  True                 True                 True   \n",
       "4490                  True                 True                 True   \n",
       "4491                 False                False                False   \n",
       "\n",
       "      EnsemblePrediction  \n",
       "0                  False  \n",
       "1                   True  \n",
       "2                   True  \n",
       "3                   True  \n",
       "4                   True  \n",
       "...                  ...  \n",
       "4487               False  \n",
       "4488               False  \n",
       "4489                True  \n",
       "4490                True  \n",
       "4491               False  \n",
       "\n",
       "[4492 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_updated = ensemble_classify_news_and_evaluate_accuracy(val_data)\n",
    "display(df_updated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for DistilBERTPrediction: 0.9850\n",
      "Accuracy for RoBERTaV1Prediction: 1.0000\n",
      "Accuracy for RoBERTaV2Prediction: 0.9800\n",
      "Accuracy for EnsemblePrediction: 0.9950\n"
     ]
    }
   ],
   "source": [
    "prediction_columns = ['DistilBERTPrediction', 'RoBERTaV1Prediction', 'RoBERTaV2Prediction', 'EnsemblePrediction']\n",
    "\n",
    "# Loop through each prediction column to calculate and print accuracy\n",
    "for column in prediction_columns:\n",
    "    correct_predictions = (df_updated[column] == df_updated['label']).sum()\n",
    "    total_predictions = len(df_updated)\n",
    "    accuracy = correct_predictions / total_predictions\n",
    "    print(f\"Accuracy for {column}: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_759123/1222044664.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_updated.rename(columns={\n"
     ]
    }
   ],
   "source": [
    "df_updated.rename(columns={\n",
    "    'DistilBERTPrediction': 'DistilBERTPrediction_Text',\n",
    "    'RoBERTaV1Prediction': 'RoBERTaV1Prediction_Text',\n",
    "    'RoBERTaV2Prediction': 'RoBERTaV2Prediction_Text',\n",
    "    'EnsemblePrediction': 'EnsemblePrediction_Text'\n",
    "}, inplace=True)\n",
    "df_updated.to_csv(\"./Constraint_Val_Labeled.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
